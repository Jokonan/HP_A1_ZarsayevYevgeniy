# Practice6_ZarsayevYevgeniy

## Отчет по Practice6

Цель данной практической работы — познакомиться с основами программирования на OpenCL и научиться использовать параллельные вычисления на CPU и GPU. В работе требовалось реализовать два вычислительных задания, сравнить их выполнение на процессоре и видеокарте, а также оценить прирост производительности. Основная идея заключается в том, чтобы показать, как параллельные вычисления позволяют значительно ускорить обработку больших объемов данных по сравнению с последовательными алгоритмами.

### Сложение двух массивов

В первом задании требовалось реализовать операцию поэлементного сложения двух массивов с использованием OpenCL. Были созданы два одинаковых по размеру массива, заполненные случайными числами. Сначала сложение выполнялось последовательно на CPU, затем та же операция была реализована на GPU с помощью OpenCL-ядра. Программа инициализировала платформу и устройство OpenCL, создавала контекст, очередь команд, загружала и компилировала ядро, передавала данные на устройство и запускала вычисления.

Результаты:

<img width="400" height="113" alt="image" src="https://github.com/user-attachments/assets/058ad3cd-118e-40ef-8905-1cfc1d565ac1" />

График:


<img width="655" height="452" alt="image" src="https://github.com/user-attachments/assets/3bc8c50d-a36e-4da0-9168-c0cb31056e50" />


По результатам выполнения было получено время работы на CPU и на GPU. GPU выполнил операцию значительно быстрее, чем CPU, при этом результаты вычислений полностью совпали. Это показывает, что даже для простой операции сложения массивов использование GPU даёт заметное ускорение за счёт параллельной обработки элементов.


Блок схема:

<img width="337" height="819" alt="image" src="https://github.com/user-attachments/assets/353cfa0a-7841-466c-a6eb-3d9f5c3e7c5f" />



### Параллельное умножение матриц

Во втором задании необходимо было реализовать параллельное умножение матриц размером N×M и M×K с использованием OpenCL. Сначала умножение было реализовано последовательно на CPU с использованием вложенных циклов. Затем была написана версия для GPU, где каждый рабочий поток вычислял один элемент результирующей матрицы. Размеры матриц передавались в ядро в качестве аргументов, а вычисления выполнялись в двумерной рабочей области.



Результаты:


<img width="342" height="122" alt="image" src="https://github.com/user-attachments/assets/e989c77d-5bac-44c8-9e4f-bd5035838d92" />

График:

<img width="622" height="394" alt="image" src="https://github.com/user-attachments/assets/ac135293-b026-4b61-bdd1-f8379fedee2f" />


Результаты показали, что GPU выполняет умножение матриц в разы быстрее, чем CPU. При этом проверка корректности подтвердила, что значения, полученные на GPU, совпадают с результатами последовательной реализации на CPU. Это подтверждает эффективность использования OpenCL для вычислительно сложных задач, таких как матричное умножение.


Блок схема:



<img width="305" height="820" alt="image" src="https://github.com/user-attachments/assets/23267055-c96e-42e8-9329-ce4253f98228" />


## Вывод


В ходе выполнения данной практической работы были изучены основы работы с OpenCL и принципы организации параллельных вычислений на CPU и GPU. В обоих заданиях было показано, что GPU значительно превосходит CPU по скорости выполнения при работе с большими массивами данных. Использование OpenCL позволяет писать кроссплатформенные программы и эффективно использовать вычислительные возможности современных видеокарт. Параллельные вычисления особенно выгодны для задач с большим количеством однотипных операций, таких как сложение массивов и умножение матриц.


# Контрольные вопросы



1. Какие основные типы памяти используются в OpenCL?

Ответ: Global - общая для всех рабочих потоков, медленная. Local - общая для группы потоков, быстрая. Private - индивидуальная для каждого потока, очень быстрая. Constant - только для чтения, для всех потоков.

2. Как настроить глобальную и локальную рабочую группу?

Ответ: Global - это общее количество операций, которые выполняют ядро. Local - это размер блока, который работает вместе и делит local память.

3. Чем отличается OpenCL от CUDA?

Ответ: CUDA работает только на NVIDIA GPU. OpenCL - кроссплатформенный, можно на CPU, GPU разных производителей.

4. Какие преимущества дает использование OpenCL?

Ответ: Можно запускать программы на разных устройствах. Параллельная обработка ускоряет вычисления. Можно использовать и CPU, и GPU одновременно.





### Сборка

!g++ task1.cpp -lOpenCL -O2 -o task1


### Запуск
!./task1

