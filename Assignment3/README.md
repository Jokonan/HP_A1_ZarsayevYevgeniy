# Assignment3_ZarsayevYevgeniy

## Отчет по работе с CUDA
В этот раз сильно постарался с оформлением, надеюсь все сделал по стандартам.

В этой работе я выполнил 4 задания, каждое из которых связано с программированием на GPU с использованием CUDA. Основная цель была познакомиться с параллельной обработкой массивов, измерением производительности разных вариантов и оптимизацией параметров блоков и сетки потоков. В процессе работы я создавал ядра для глобальной и shared памяти, экспериментировал с размерами блоков и проверял, как коалесцированный и некоалесцированный доступ к памяти влияет на скорость выполнения программ. Все задания были запущены на GPU с помощью Google Colab, а результаты я измерял с помощью встроенных таймеров CUDA.

## Задание 1 – Поэлементное умножение массива
В первом задании требовалось реализовать программу, которая умножает каждый элемент массива на число. Нужно было сделать две версии: с использованием глобальной памяти и с использованием shared памяти.

Я получил следующие результаты:

<img width="413" height="121" alt="image" src="https://github.com/user-attachments/assets/d15b5741-c018-49eb-bbbb-75fbf44fb3b0" />

Это показывает, что оба варианта работают корректно, но shared память работает почти в два раза быстрее, что подтверждает, что использование быстрой памяти ускоряет обработку данных на GPU.

Вот блок схема для этого задания:

<img width="433" height="833" alt="image" src="https://github.com/user-attachments/assets/913750fe-5667-42fa-ac9f-fbce94421f68" />

## Задание 2 – Сложение массивов и влияние размера блока
Во втором задании нужно было сложить два массива и исследовать, как размер блока потоков влияет на производительность программы. Я проверял три размера блока: 128, 256 и 512 потоков.

Результаты:

<img width="525" height="103" alt="image" src="https://github.com/user-attachments/assets/d77ace43-bca0-4977-bb67-b9479db95262" />

Все блоки дают правильный результат, но при увеличении блока до 256 потоков скорость выполнения сильно улучшается. Блок размером 512 потоков работает почти так же быстро, как 256, что говорит о том, что дальше увеличение размера блока не даёт значительного прироста.

Блок схема:

<img width="420" height="808" alt="image" src="https://github.com/user-attachments/assets/a3b2855e-bdb4-4735-9f73-f3be9c3691e7" />

## Задание 3 – Коалесцированный и некоалесцированный доступ
В третьем задании нужно было сравнить, как скорость работы меняется при последовательном коалесцированном и «разбросанном», то есть некоалесцированном доступе к глобальной памяти.

Результаты:

<img width="455" height="87" alt="image" src="https://github.com/user-attachments/assets/8d598eaf-398e-4895-8253-2563972fdab5" />

Оба варианта дают правильный результат (2), но при некоалесцированном доступе время выполнения сильно увеличивается (почти в 50 раз). Это наглядно показывает, насколько важно правильно организовывать доступ к памяти на GPU для ускорения программ.

Блок схема:

<img width="359" height="817" alt="image" src="https://github.com/user-attachments/assets/6ecded86-6980-4b50-8b11-639d648629ba" />

## Задание 4 – Оптимизация конфигурации блоков
В четвертом задании нужно было подобрать оптимальные параметры сетки и блоков потоков для одного из предыдущих заданий и сравнить с неоптимальной конфигурацией.

Результаты:

<img width="574" height="90" alt="image" src="https://github.com/user-attachments/assets/8e1f02e2-2752-40c6-8cca-3d461a0336c2" />

Блок схема:

<img width="308" height="761" alt="image" src="https://github.com/user-attachments/assets/1eacf80f-5dde-4fe3-acf0-2a8090cd8b7f" />

# Вывод
В ходе работы я убедился, что параллельная обработка на GPU даёт значительное ускорение, особенно при правильном использовании shared памяти и оптимальной конфигурации блоков. Также я увидел, как критично влияет способ доступа к памяти (коалесцированный или нет) на производительность. Все четыре задания помогли мне лучше понять принципы работы CUDA и важность оптимизации для ускорения вычислений.

## Контрольные вопросы
1. Какие основные типы памяти существуют в архитектуре CUDA и чем они отличаются по скорости доступа?

Ответ: Глобальная память - медленная, общая для всех потоков. Shared память - быстрая, для потоков одного блока. Регистры - самые быстрые, но у каждого потока свои.

2. В каких случаях использование разделяемой памяти позволяет ускорить выполнение CUDA-программы?

Ответ: Когда несколько потоков блока работают с одними и теми же данными. Сначала загружаем в shared память, потом используем - так гораздо быстрее, чем читать из глобальной каждый раз.

3. Как шаблон доступа к глобальной памяти влияет на производительность GPU-программы?

Ответ: Если потоки читают подряд (коалесцировано) - быстро. Если читают разбросано - медленно. GPU оптимизирован под последовательный доступ.

4. Почему одинаковый алгоритм на GPU может показывать разное время выполнения при разных способах обращения к памяти?

Ответ:  Потому что скорость работы зависит не только от вычислений, но и от того, как данные читаются из памяти. Неправильный доступ сильно тормозит ядро.

5. Как размер блока потоков влияет на производительность CUDA-ядра?

Ответ: Если блок маленький - GPU не полностью загружен. Если блок слишком большой - могут быть лишние задержки и синхронизация. Оптимальный размер даёт максимальную скорость.

6. Что такое варп и почему важно учитывать его при разработке CUDA-программ?

Ответ: Варп - группа из 32 потоков, которые выполняются одновременно. Если потоки варпа работают по-разному или ветвятся, это замедляет выполнение.

7. Какие факторы необходимо учитывать при выборе конфигурации сетки и блоков потоков?

Ответ: Размер массива, размер блока, количество потоков на GPU, ограничение по shared памяти и регистрах. Всё это влияет на скорость и загрузку GPU.

8. Почему оптимизация CUDA-программы часто начинается с анализа работы с памятью, а не с изменения алгоритма?

Ответ: Потому что медленные обращения к памяти обычно сильнее тормозят программу, чем сами вычисления. Оптимизация памяти даёт самый заметный прирост скорости.



### Сборка
!nvcc task.cu -O2 -gencode arch=compute_75,code=sm_75 -o task

### Запуск
!./task
